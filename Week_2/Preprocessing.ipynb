{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT LIBRARIES\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from date_time_preprocessor import *\n",
    "\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(406045, 8)\n"
     ]
    }
   ],
   "source": [
    "# IMPORT DATA\n",
    "\n",
    "df_raw = pd.read_csv('~/Documents/FullStack_DS/data/airline_delay_train.csv')\n",
    "print(df_raw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running feature engineering\n",
      "(406045, 13)\n"
     ]
    }
   ],
   "source": [
    "# Applying date_time_preprocessor.py\n",
    "\n",
    "training = feat_eng_datetime(df_raw)\n",
    "print(training.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = training.dep_delayed_15min\n",
    "X_train = training.drop('dep_delayed_15min', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE VAR TYPES\n",
    "\n",
    "numerical_cols = list(X_train.select_dtypes(include=['int64']).columns)\n",
    "categorical_cols = list(X_train.select_dtypes(include=['object', 'category']).columns)\n",
    "datetime_cols = list(X_train.select_dtypes(include=['datetime64[ns]']).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRE PROCESSING PIPELINE\n",
    "\n",
    "# Numerical Features\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median', add_indicator=True)),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# Categorical Features\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing', add_indicator=True)),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "# Date Time Features\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_feats),\n",
    "        ('cat', categorical_transformer, cat_feats)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL BUILD PROTOTYPE\n",
    "\n",
    "rf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', RandomForestClassifier())])\n",
    "\n",
    "param_grid = {'classifier__n_estimators': [400]}\n",
    "\n",
    "print('Running Model')\n",
    "CV = GridSearchCV(rf, param_grid, n_jobs= -1,scoring='roc_auc')\n",
    "CV.fit(X_train, y_train)  \n",
    "#print(CV.get_params())\n",
    "#print(CV.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VALIDATING MODEL PROTOTYPE\n",
    "\n",
    "y_pred = CV.predict(X_validation)\n",
    "print(classification_report(y_validation, y_pred, target_names=target_names))\n",
    "print(\"{}{}\".format(\"Cross - Validation: \", CV.best_score_))\n",
    "print(\"{}{}\".format(\"Validation: \", CV.score(X_validation,y_validation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Break Training into Train & Validation\n",
    "X = train.drop([\"dep_delayed_15min\",\"FlightDate\",\"DepTime\"], axis=1)\n",
    "y = train[\"dep_delayed_15min\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    random_state=21,\n",
    "    test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_works = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                            ('model', RandomForestClassifier())])\n",
    "pipe_works.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_preds = pipe_works.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_loss(y_test, X_test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Holdout\n",
    "ho_X_preds = pipe_works.predict_proba(ho_X)\n",
    "log_loss(ho_y, ho_X_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation Pipeline\n",
    "\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', LogisticRegression())])\n",
    "\n",
    "param_grid = {\n",
    "    'preprocessor__num__imputer__strategy': ['mean', 'median'],\n",
    "    'classifier__C': [0.1, 1.0, 10, 100],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print((\"best logistic regression from grid search: %.3f\"\n",
    "       % grid_search.score(X_test, y_test)))\n",
    "\n",
    "#clf.fit(X_train, y_train)\n",
    "#print(\"model score: %.3f\" % clf.score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
