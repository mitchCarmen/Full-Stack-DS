{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from date_time_preprocessor import *\n",
    "\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import log_loss, classification_report, roc_auc_score\n",
    "import category_encoders as ce\n",
    "import lightgbm as lgb\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/mitchell.carmen/Documents/FullStack_DS/'\n",
    "df_raw = pd.read_csv(path + 'data/airline_delay_train.csv')\n",
    "print(df_raw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying date_time_preprocessor.py\n",
    "training = feat_eng_datetime(df_raw)\n",
    "print(training.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = training.drop([\"dep_delayed_15min\"], axis=1)\n",
    "y = training[\"dep_delayed_15min\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    random_state=21,\n",
    "    test_size=0.1,\n",
    "    stratify=y)\n",
    "\n",
    "# print(X_train.shape)\n",
    "# print(y_train.shape)\n",
    "# print(X_test.shape)\n",
    "# print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATE VAR TYPES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = list(X_train.select_dtypes(include=['int64']).columns)\n",
    "categorical_cols = list(X_train.select_dtypes(include=['object', 'category']).columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRE PROCESSING PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value= -9999)),\n",
    "    ('catencoder', ce.ordinal.OrdinalEncoder())])\n",
    "#     ('targetencoder', ce.target_encoder.TargetEncoder(min_samples_leaf = 1, smoothing = 1))])\n",
    "#     ('countencoder', ce.count.CountEncoder(min_group_size = 10))])\n",
    "#     ('onehotencoder', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL BUILD PROTOTYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## hyperparameter tuning for Light GBM\n",
    "\n",
    "LGBM = lgb.LGBMClassifier(boosting_type='gbdt',random_state = 99,\n",
    "                          class_weight='balanced', objective= 'binary')\n",
    "\n",
    "param_grid = { \n",
    "    'lgbmclassifier__n_estimators': [150,250],\n",
    "    'lgbmclassifier__feature_fraction': ['auto', 'sqrt', 0.7],\n",
    "    'lgbmclassifier__max_depth' : [6,7,8],\n",
    "    'lgbmclassifier__learning_rate' : [0.1, 0.01],\n",
    "    'lgbmclassifier__num_leaves' : [70,80],\n",
    "    'lgbmclassifier__min_data_in_leaf' : [20, 50, 100]\n",
    "}\n",
    "\n",
    "lgbm = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('lgbmclassifier', LGBM)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_lgbm = GridSearchCV(lgbm, cv= 3, n_jobs= -1, param_grid= param_grid, scoring='roc_auc')\n",
    "grid_lgbm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_lgbm.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_lgbm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_lgbm.predict(X_test)\n",
    "\n",
    "roc_auc_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAVE PICKLE DUMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_lgbm.feature_names = list(X_train.columns.values)\n",
    "pickle.dump(grid_lgbm, open(path + 'LGBM_flights_model.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPEN PICKLE DUMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_lgbm = pickle.load(open(path + 'LGBM_flights_model.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Holdout Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import HO data\n",
    "test_df = pd.read_csv(path + 'data/airline_delay_test.csv')\n",
    "# Preprocess DateTime features\n",
    "test_df = feat_eng_datetime(test_df)\n",
    "test_df_y = test_df.dep_delayed_15min\n",
    "test_df_x = test_df.drop(['dep_delayed_15min'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on HO data\n",
    "test_pred = grid_lgbm.predict(test_df_x)\n",
    "\n",
    "roc_auc_score(test_df_y,test_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
